{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pytorch_msssim import MS_SSIM\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "if torch.cuda.is_available():  \n",
    "    device = \"cuda:0\"\n",
    "else:  \n",
    "    device = \"cpu\"\n",
    "\n",
    "# path to font list\n",
    "fonts_csv = \"fonts.csv\"\n",
    "# root directory for dataset\n",
    "dataroot = \"images\"\n",
    "# number of workers for dataloader\n",
    "workers = 0\n",
    "# number of epochs\n",
    "num_epochs = 200\n",
    "# batch size for training\n",
    "batch_size = 16\n",
    "# height and width of input image\n",
    "img_size = 64\n",
    "# the alphabet characters\n",
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "# number of channels\n",
    "nc0 = 1 * len(alphabet)\n",
    "nc1 = 4 * len(alphabet)\n",
    "nc2 = 8 * len(alphabet)\n",
    "nc3 = 16 * len(alphabet)\n",
    "# disciminator channels\n",
    "dc0 = 1\n",
    "dc1 = 8\n",
    "dc2 = 16\n",
    "dc3 = 32\n",
    "# threshold\n",
    "thresh = 0\n",
    "# learning rate\n",
    "lr = 0.0006\n",
    "# beta1 for Adam\n",
    "beta1 = 0.5\n",
    "# real label\n",
    "real_label = 1.0\n",
    "# fake label\n",
    "fake_label = 0.0\n",
    "# number of extra times to run the discriminator than the encdec per epoch\n",
    "num_dis = 1\n",
    "# coefficient of the discriminator loss in training\n",
    "cof_dis = 7e-3\n",
    "# number of patches to sample\n",
    "num_patches = 3\n",
    "# letter we use to generate all the other letters\n",
    "base_letter = 'R'\n",
    "# letter we are trying to generate\n",
    "gen_letter = 'B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FontDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.fontlist = pd.read_csv(csv_file, sep=' ')\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fontlist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        sample = {}\n",
    "        for c in alphabet:\n",
    "            path = os.path.join(self.root_dir, c, f'{idx}.npy')\n",
    "            img = np.load(path)\n",
    "            img = img[img_size//2:img_size//2 + img_size, img_size//2:img_size//2 + img_size, :]\n",
    "            img = self.transform(img)\n",
    "            sample[c] = img.type(torch.cuda.FloatTensor)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://discuss.pytorch.org/t/is-there-anyway-to-do-gaussian-filtering-for-an-image-2d-3d-in-pytorch/12351/3\n",
    "def get_gaussian_kernel(kernel_size=3, sigma=2, channels=3):\n",
    "    # Create a x, y coordinate grid of shape (kernel_size, kernel_size, 2)\n",
    "    x_coord = torch.arange(kernel_size)\n",
    "    x_grid = x_coord.repeat(kernel_size).view(kernel_size, kernel_size)\n",
    "    y_grid = x_grid.t()\n",
    "    xy_grid = torch.stack([x_grid, y_grid], dim=-1).float()\n",
    "\n",
    "    mean = (kernel_size - 1)/2.\n",
    "    variance = sigma**2.\n",
    "\n",
    "    # Calculate the 2-dimensional gaussian kernel which is\n",
    "    # the product of two gaussian distributions for two different\n",
    "    # variables (in this case called x and y)\n",
    "    gaussian_kernel = (1./(2.*math.pi*variance)) *\\\n",
    "                      torch.exp(\n",
    "                          -torch.sum((xy_grid - mean)**2., dim=-1) /\\\n",
    "                          (2*variance)\n",
    "                      )\n",
    "\n",
    "    # Make sure sum of values in gaussian kernel equals 1.\n",
    "    gaussian_kernel = gaussian_kernel / torch.sum(gaussian_kernel)\n",
    "\n",
    "    # Reshape to 2d depthwise convolutional weight\n",
    "    gaussian_kernel = gaussian_kernel.view(1, 1, kernel_size, kernel_size)\n",
    "    gaussian_kernel = gaussian_kernel.repeat(channels, 1, 1, 1)\n",
    "\n",
    "    gaussian_filter = nn.Conv2d(in_channels=channels, out_channels=channels,\n",
    "                                kernel_size=kernel_size, groups=channels, bias=False, padding=1)\n",
    "\n",
    "    gaussian_filter.weight.data = gaussian_kernel\n",
    "    gaussian_filter.weight.requires_grad = False\n",
    "    \n",
    "    return gaussian_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.conv01 = nn.Conv2d(dc0, dc1, 3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(dc1, dc2, 3, padding=1)\n",
    "        self.conv23 = nn.Conv2d(dc2, dc3, 3, padding=1)\n",
    "        \n",
    "        self.conv33 = nn.Conv2d(dc3, dc3, 3, padding=1)\n",
    "        self.conv32 = nn.Conv2d(dc3, nc0, 3, padding=1)\n",
    "        \n",
    "        self.conv0same = nn.Conv2d(nc0, nc0, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, return_indices=True)\n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.threshold = nn.Threshold(thresh, 0)\n",
    "        \n",
    "        self.gaussian_filter = get_gaussian_kernel(kernel_size = 3, sigma=2, channels=nc0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv01(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv12(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv23(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x, idx1 = self.pool(x)\n",
    "        \n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x, idx2 = self.pool(x)\n",
    "        \n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x, idx3 = self.pool(x)\n",
    "        \n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        \n",
    "        x = self.unpool(x, idx3)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        \n",
    "        x = self.unpool(x, idx2)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv33(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        \n",
    "        x = self.unpool(x, idx1)\n",
    "        x = self.conv32(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        \n",
    "        x = self.gaussian_filter(x)\n",
    "        x = self.conv0same(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.conv0same(x)\n",
    "        \n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv0 = nn.Conv2d(nc0, nc2, 3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2stri = nn.Conv2d(nc2, nc2, 4, stride=2, padding=1)\n",
    "        self.conv2same = nn.Conv2d(nc2, nc2, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(nc2, nc3, 4, stride=2, padding=1)\n",
    "        self.norm3 = nn.BatchNorm2d(nc3)\n",
    "        self.conv3same = nn.Conv2d(nc3, nc3, 3, padding=1)\n",
    "        self.conv3back = nn.Conv2d(nc3, nc2, 3, padding=1)\n",
    "        self.conv0back = nn.Conv2d(nc2, nc0, 3, padding=1)\n",
    "        self.flat = nn.Flatten(2)\n",
    "        self.linear = nn.Linear(img_size//8 * img_size//8, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.flat1 = nn.Flatten()\n",
    "        \n",
    "    def forward(self, input):\n",
    "        # nc0 x img_size x img_size\n",
    "        out = self.conv0(input)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # nc2 x img_size x img_size\n",
    "        out = self.conv2stri(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # nc2 x img_size/2 x img_size/2\n",
    "        out = self.conv2stri(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        # nc2 x img_size/4 x img_size/4\n",
    "        out = self.conv2same(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2same(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.norm3(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv3same(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3back(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.conv0back(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        out = self.linear(out)\n",
    "        out = self.flat1(out)\n",
    "        out = self.sigmoid(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add all the tensors together along the channel dimension\n",
    "def concat_tensors(data):\n",
    "    tensor = None\n",
    "    \n",
    "    for c in alphabet:\n",
    "        if tensor == None:\n",
    "            tensor = data[c]\n",
    "        else:\n",
    "            tensor = torch.cat((tensor, data[c]), 1)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossD_list = []\n",
    "loss_disc_list = []\n",
    "loss_l1_list = []\n",
    "loss_ssim_list = []\n",
    "loss_local_list = []\n",
    "val_set = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset = FontDataset(csv_file=fonts_csv, \n",
    "                        root_dir=dataroot, \n",
    "                        transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(0.5, 0.5),\n",
    "#                             AddGaussianNoise(0., 0.05),\n",
    "                        ]))\n",
    "    global val_set\n",
    "    testset_size = len(dataset) // 5 * 4\n",
    "    train_set, val_set = random_split(dataset, [testset_size, len(dataset) - testset_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_data = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "    \n",
    "    encdec = EncoderDecoder()\n",
    "    encdec.to(device)\n",
    "    # use this line to continue training instead of starting a new one\n",
    "    encdec.load_state_dict(torch.load('encdec-Copy8.pt'))\n",
    "    \n",
    "    criterionED_l1 = nn.L1Loss()\n",
    "    criterionED_ssim = MS_SSIM(win_size=3, data_range=1, size_average=True, channel=nc0)\n",
    "    optimizerED = optim.Adam(encdec.parameters(), lr=lr)\n",
    "\n",
    "    disc = Discriminator()\n",
    "    disc.to(device)\n",
    "    disc.load_state_dict(torch.load('disc-Copy1.pt'))\n",
    "    \n",
    "    criterionD = nn.BCELoss()\n",
    "    optimizerD = optim.Adam(disc.parameters(), lr=lr)\n",
    "    \n",
    "    # training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        running_lossD = 0.0\n",
    "        running_loss_disc = 0.0\n",
    "        running_loss_l1 = 0.0\n",
    "        running_loss_ssim = 0.0\n",
    "        running_loss_local = 0.0\n",
    "        \n",
    "        # train discrimintor num_dis extra times\n",
    "        for it in range(num_dis):\n",
    "            for i, data in enumerate(train_data):\n",
    "                train_batch = concat_tensors(data)\n",
    "                disc.zero_grad()\n",
    "\n",
    "                b_size = train_batch.size(0)\n",
    "                c_size = train_batch.size(1)\n",
    "                label = torch.full((b_size,c_size,), real_label, dtype=torch.float, device=device)\n",
    "\n",
    "                outputD = disc(train_batch)\n",
    "                lossD_real = criterionD(outputD, label)\n",
    "                lossD_real.backward()\n",
    "\n",
    "                # all fake batch\n",
    "                outputED = encdec(data[base_letter])\n",
    "                label.fill_(fake_label)\n",
    "                outputD = disc(outputED.detach())\n",
    "                lossD_fake = criterionD(outputD, label)\n",
    "                lossD_fake.backward()\n",
    "\n",
    "                lossD = lossD_real + lossD_fake\n",
    "                optimizerD.step()\n",
    "#         print('finished updating dis')\n",
    "                \n",
    "        for i, data in enumerate(train_data):\n",
    "            train_batch = concat_tensors(data)\n",
    "            train_batch.to(device)\n",
    "            ###########################\n",
    "            # update disc\n",
    "            ###########################\n",
    "            disc.zero_grad()\n",
    "            # all real batch\n",
    "            b_size = train_batch.size(0)\n",
    "            c_size = train_batch.size(1)\n",
    "            label = torch.full((b_size,c_size,), real_label, dtype=torch.float, device=device)\n",
    "            label.to(device)\n",
    "            outputD = disc(train_batch)\n",
    "            lossD_real = criterionD(outputD, label)\n",
    "            lossD_real.backward()\n",
    "            \n",
    "            # all fake batch\n",
    "            data[base_letter].to(device)\n",
    "            outputED = encdec(data[base_letter])\n",
    "            \n",
    "            label.fill_(fake_label)\n",
    "            outputD = disc(outputED.detach())\n",
    "            lossD_fake = criterionD(outputD, label)\n",
    "            lossD_fake.backward()\n",
    "\n",
    "            lossD = lossD_real + lossD_fake\n",
    "            optimizerD.step()\n",
    "\n",
    "            ###########################\n",
    "            # update encdec\n",
    "            ###########################\n",
    "            encdec.zero_grad()\n",
    "            # rerun disc\n",
    "            label.fill_(real_label)\n",
    "            outputD = disc(outputED)\n",
    "            lossED_disc = criterionD(outputD, label)\n",
    "            # run encdec\n",
    "            outputED = encdec(data[base_letter])\n",
    "            lossED_l1 = criterionED_l1(outputED, train_batch)\n",
    "            \n",
    "            # calculate local loss\n",
    "            lossED_local = 0.0\n",
    "            for _ in range(num_patches):\n",
    "                x = np.random.randint(16, 48)\n",
    "                y = np.random.randint(16, 48)\n",
    "                for j, c in enumerate(alphabet):\n",
    "                    outputED_patch = outputED[:, j, x-8:x+8, y-8:y+8]\n",
    "                    datac2_patch = data[c][:, 0, x-8:x+8, y-8:y+8]\n",
    "                    outputED_patch = (outputED_patch + 1) / 2\n",
    "                    datac2_patch = (datac2_patch + 1) / 2\n",
    "                    lossED_local += criterionED_l1(outputED_patch, datac2_patch)\n",
    "            \n",
    "            # backprop to update model\n",
    "            outputED_norm = (outputED + 1) / 2\n",
    "            train_norm = (train_batch + 1) / 2\n",
    "            lossED_ssim = 1 - criterionED_ssim(outputED_norm, train_norm)\n",
    "\n",
    "            lossED = 0.16 * lossED_l1 + 0.84 * lossED_ssim + lossED_local/len(alphabet)/num_patches\n",
    "            lossED.backward()\n",
    "            optimizerED.step()\n",
    "    \n",
    "            running_lossD += lossD.item()\n",
    "            running_loss_disc += lossED_disc.item()\n",
    "            running_loss_l1 += lossED_l1.item()\n",
    "            running_loss_ssim += lossED_ssim.item()\n",
    "            running_loss_local += lossED_local.item()\n",
    "            \n",
    "            # check on the training process\n",
    "            if i % 25 == 24:\n",
    "                print(f\"Epoch {epoch+1}, Iteration {i+1}, Loss D {running_lossD}, Loss Disc {running_loss_disc}, Loss L1 {running_loss_l1}, Loss SSIM {running_loss_ssim}, Loss Local {running_loss_local}\")\n",
    "                lossD_list.append(running_lossD)\n",
    "                loss_disc_list.append(running_loss_disc)\n",
    "                loss_l1_list.append(running_loss_l1)\n",
    "                loss_ssim_list.append(running_loss_ssim)\n",
    "                loss_local_list.append(running_loss_local)\n",
    "                running_lossD = 0.0\n",
    "                running_loss_disc = 0.0\n",
    "                running_loss_l1 = 0.0\n",
    "                running_loss_ssim = 0.0\n",
    "                running_loss_local = 0.0\n",
    "                \n",
    "                fig = plt.figure(figsize=(8, 8))\n",
    "                fig.add_subplot(1, 2, 1)\n",
    "                plt.imshow(data['A'][0].permute(1, 2, 0).cpu().detach().numpy(), cmap='gray')\n",
    "                fig.add_subplot(1, 2, 2)\n",
    "                plt.imshow(outputED[0,0].cpu().detach().numpy(), cmap='gray')\n",
    "                plt.show()\n",
    "                torch.save(encdec.state_dict(), 'encdec.pt')\n",
    "                torch.save(disc.state_dict(), 'disc.pt')\n",
    "\n",
    "        \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the losses\n",
    "import pickle\n",
    "\n",
    "with open(\"loss_l1\", \"wb\") as f:\n",
    "    pickle.dump(loss_l1_list, f)\n",
    "    \n",
    "with open(\"lossD\", \"wb\") as f:\n",
    "    pickle.dump(lossD_list, f)\n",
    "\n",
    "with open(\"loss_disc\", \"wb\") as f:\n",
    "    pickle.dump(loss_disc_list, f)\n",
    "\n",
    "with open(\"loss_ssim\", \"wb\") as f:\n",
    "    pickle.dump(loss_ssim_list, f)\n",
    "\n",
    "with open(\"loss_local\", \"wb\") as f:\n",
    "    pickle.dump(loss_local_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"loss_local\", \"rb\") as f:\n",
    "    x=pickle.load(f)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(loss_l1_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
